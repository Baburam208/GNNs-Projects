{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e03b657-c6ea-4dd5-984d-a90dd9a61d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad157f3-645b-4a79-abaa-374675265d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"D:\\\\Baburam\\\\Graph Project\\\\project\\\\train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351e221e-6925-4484-bcf0-afa20a691114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total dataset: 26604\n",
      "train_dataset: 18622\n",
      "val_dataset: 7982\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for class_i in os.listdir(dataset_path):\n",
    "    file_path = os.path.join(dataset_path, class_i)\n",
    "    for filename in os.listdir(file_path):\n",
    "        filename_path = os.path.join(file_path, filename)\n",
    "        dataset.append(filename_path)\n",
    "    \n",
    "total = len(dataset)\n",
    "\n",
    "dataset = random.sample(dataset, len(dataset))\n",
    "\n",
    "train_dataset = dataset[:int(total * 0.7)]\n",
    "val_dataset = dataset[int(total * 0.7):]\n",
    "\n",
    "print(f\"total dataset: {len(dataset)}\")\n",
    "print(f\"train_dataset: {len(train_dataset)}\")\n",
    "print(f\"val_dataset: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af94a8de-1239-4330-904d-2159cd0b5106",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = list()\n",
    "for train_ds in train_dataset:\n",
    "    train_list.append(torch.load(train_ds))\n",
    "    \n",
    "val_list = list()\n",
    "for val_ds in val_dataset:\n",
    "    val_list.append(torch.load(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c90619f-d6d3-4459-a545-f7f2a3304783",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_list, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_list, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da46ac0c-18fd-4245-9ab2-ab796c38f1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b80088d0-93ce-42fb-8e3d-e3d1248b69bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GraphConv(3, 16)\n",
      "  (conv2): GraphConv(16, 16)\n",
      "  (lin): Linear(in_features=16, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GraphConv\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GraphConv(3, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        # self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 7)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # x = x.relu()\n",
    "        # x = self.conv3(x, edge_index)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GNN(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf8867b-e59e-4dea-9d82-dcf7fbd8678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f425fd-c69c-4ba7-a1a4-907b94d32e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e2d1441-85a9-46d1-a708-15466e2aac64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.3587, Validation Acc: 0.3510\n",
      "Epoch: 002, Train Acc: 0.3922, Validation Acc: 0.3865\n",
      "Epoch: 003, Train Acc: 0.3886, Validation Acc: 0.3831\n",
      "Epoch: 004, Train Acc: 0.3551, Validation Acc: 0.3499\n",
      "Epoch: 005, Train Acc: 0.3809, Validation Acc: 0.3767\n",
      "Epoch: 006, Train Acc: 0.3820, Validation Acc: 0.3748\n",
      "Epoch: 007, Train Acc: 0.3839, Validation Acc: 0.3799\n",
      "Epoch: 008, Train Acc: 0.3922, Validation Acc: 0.3869\n",
      "Epoch: 009, Train Acc: 0.3915, Validation Acc: 0.3816\n",
      "Epoch: 010, Train Acc: 0.3850, Validation Acc: 0.3766\n",
      "Epoch: 011, Train Acc: 0.3876, Validation Acc: 0.3836\n",
      "Epoch: 012, Train Acc: 0.3790, Validation Acc: 0.3697\n",
      "Epoch: 013, Train Acc: 0.3284, Validation Acc: 0.3225\n",
      "Epoch: 014, Train Acc: 0.3396, Validation Acc: 0.3343\n",
      "Epoch: 015, Train Acc: 0.3849, Validation Acc: 0.3796\n",
      "Epoch: 016, Train Acc: 0.3763, Validation Acc: 0.3702\n",
      "Epoch: 017, Train Acc: 0.3778, Validation Acc: 0.3723\n",
      "Epoch: 018, Train Acc: 0.3983, Validation Acc: 0.3921\n",
      "Epoch: 019, Train Acc: 0.3905, Validation Acc: 0.3786\n",
      "Epoch: 020, Train Acc: 0.3707, Validation Acc: 0.3667\n",
      "Epoch: 021, Train Acc: 0.3744, Validation Acc: 0.3686\n",
      "Epoch: 022, Train Acc: 0.3811, Validation Acc: 0.3777\n",
      "Epoch: 023, Train Acc: 0.3907, Validation Acc: 0.3839\n",
      "Epoch: 024, Train Acc: 0.3949, Validation Acc: 0.3879\n",
      "Epoch: 025, Train Acc: 0.3680, Validation Acc: 0.3634\n",
      "Epoch: 026, Train Acc: 0.3814, Validation Acc: 0.3785\n",
      "Epoch: 027, Train Acc: 0.3702, Validation Acc: 0.3648\n",
      "Epoch: 028, Train Acc: 0.3951, Validation Acc: 0.3864\n",
      "Epoch: 029, Train Acc: 0.3979, Validation Acc: 0.3896\n",
      "Epoch: 030, Train Acc: 0.3355, Validation Acc: 0.3370\n",
      "Epoch: 031, Train Acc: 0.3733, Validation Acc: 0.3701\n",
      "Epoch: 032, Train Acc: 0.3895, Validation Acc: 0.3829\n",
      "Epoch: 033, Train Acc: 0.3797, Validation Acc: 0.3711\n",
      "Epoch: 034, Train Acc: 0.3893, Validation Acc: 0.3856\n",
      "Epoch: 035, Train Acc: 0.3285, Validation Acc: 0.3227\n",
      "Epoch: 036, Train Acc: 0.3401, Validation Acc: 0.3368\n",
      "Epoch: 037, Train Acc: 0.3989, Validation Acc: 0.3940\n",
      "Epoch: 038, Train Acc: 0.3863, Validation Acc: 0.3804\n",
      "Epoch: 039, Train Acc: 0.3844, Validation Acc: 0.3805\n",
      "Epoch: 040, Train Acc: 0.3903, Validation Acc: 0.3830\n",
      "Epoch: 041, Train Acc: 0.3838, Validation Acc: 0.3740\n",
      "Epoch: 042, Train Acc: 0.3578, Validation Acc: 0.3508\n",
      "Epoch: 043, Train Acc: 0.3984, Validation Acc: 0.3948\n",
      "Epoch: 044, Train Acc: 0.3726, Validation Acc: 0.3696\n",
      "Epoch: 045, Train Acc: 0.3507, Validation Acc: 0.3441\n",
      "Epoch: 046, Train Acc: 0.3659, Validation Acc: 0.3611\n",
      "Epoch: 047, Train Acc: 0.3614, Validation Acc: 0.3563\n",
      "Epoch: 048, Train Acc: 0.3882, Validation Acc: 0.3862\n",
      "Epoch: 049, Train Acc: 0.3980, Validation Acc: 0.3921\n",
      "Epoch: 050, Train Acc: 0.3872, Validation Acc: 0.3776\n",
      "Epoch: 051, Train Acc: 0.3473, Validation Acc: 0.3453\n",
      "Epoch: 052, Train Acc: 0.3912, Validation Acc: 0.3820\n",
      "Epoch: 053, Train Acc: 0.3982, Validation Acc: 0.3894\n",
      "Epoch: 054, Train Acc: 0.3742, Validation Acc: 0.3638\n",
      "Epoch: 055, Train Acc: 0.3659, Validation Acc: 0.3596\n",
      "Epoch: 056, Train Acc: 0.3857, Validation Acc: 0.3758\n",
      "Epoch: 057, Train Acc: 0.3828, Validation Acc: 0.3768\n",
      "Epoch: 058, Train Acc: 0.3674, Validation Acc: 0.3651\n",
      "Epoch: 059, Train Acc: 0.3842, Validation Acc: 0.3809\n",
      "Epoch: 060, Train Acc: 0.3799, Validation Acc: 0.3741\n",
      "Epoch: 061, Train Acc: 0.3986, Validation Acc: 0.3906\n",
      "Epoch: 062, Train Acc: 0.3963, Validation Acc: 0.3856\n",
      "Epoch: 063, Train Acc: 0.3831, Validation Acc: 0.3791\n",
      "Epoch: 064, Train Acc: 0.4046, Validation Acc: 0.3954\n",
      "Epoch: 065, Train Acc: 0.3887, Validation Acc: 0.3820\n",
      "Epoch: 066, Train Acc: 0.3934, Validation Acc: 0.3856\n",
      "Epoch: 067, Train Acc: 0.3917, Validation Acc: 0.3831\n",
      "Epoch: 068, Train Acc: 0.3603, Validation Acc: 0.3581\n",
      "Epoch: 069, Train Acc: 0.3808, Validation Acc: 0.3705\n",
      "Epoch: 070, Train Acc: 0.3697, Validation Acc: 0.3643\n",
      "Epoch: 071, Train Acc: 0.3952, Validation Acc: 0.3885\n",
      "Epoch: 072, Train Acc: 0.4017, Validation Acc: 0.3929\n",
      "Epoch: 073, Train Acc: 0.3838, Validation Acc: 0.3776\n",
      "Epoch: 074, Train Acc: 0.3923, Validation Acc: 0.3820\n",
      "Epoch: 075, Train Acc: 0.3488, Validation Acc: 0.3434\n",
      "Epoch: 076, Train Acc: 0.3624, Validation Acc: 0.3559\n",
      "Epoch: 077, Train Acc: 0.3973, Validation Acc: 0.3872\n",
      "Epoch: 078, Train Acc: 0.3802, Validation Acc: 0.3748\n",
      "Epoch: 079, Train Acc: 0.3952, Validation Acc: 0.3886\n",
      "Epoch: 080, Train Acc: 0.3547, Validation Acc: 0.3487\n",
      "Epoch: 081, Train Acc: 0.3920, Validation Acc: 0.3875\n",
      "Epoch: 082, Train Acc: 0.3798, Validation Acc: 0.3727\n",
      "Epoch: 083, Train Acc: 0.4075, Validation Acc: 0.4023\n",
      "Epoch: 084, Train Acc: 0.3916, Validation Acc: 0.3849\n",
      "Epoch: 085, Train Acc: 0.3975, Validation Acc: 0.3916\n",
      "Epoch: 086, Train Acc: 0.4060, Validation Acc: 0.3939\n",
      "Epoch: 087, Train Acc: 0.4041, Validation Acc: 0.3948\n",
      "Epoch: 088, Train Acc: 0.3951, Validation Acc: 0.3871\n",
      "Epoch: 089, Train Acc: 0.3760, Validation Acc: 0.3675\n",
      "Epoch: 090, Train Acc: 0.3618, Validation Acc: 0.3578\n",
      "Epoch: 091, Train Acc: 0.3826, Validation Acc: 0.3775\n",
      "Epoch: 092, Train Acc: 0.4073, Validation Acc: 0.3984\n",
      "Epoch: 093, Train Acc: 0.3977, Validation Acc: 0.3874\n",
      "Epoch: 094, Train Acc: 0.4027, Validation Acc: 0.3976\n",
      "Epoch: 095, Train Acc: 0.3908, Validation Acc: 0.3836\n",
      "Epoch: 096, Train Acc: 0.3010, Validation Acc: 0.2973\n",
      "Epoch: 097, Train Acc: 0.4099, Validation Acc: 0.4024\n",
      "Epoch: 098, Train Acc: 0.4009, Validation Acc: 0.3911\n",
      "Epoch: 099, Train Acc: 0.3807, Validation Acc: 0.3732\n",
      "Epoch: 100, Train Acc: 0.4019, Validation Acc: 0.3949\n",
      "Epoch: 101, Train Acc: 0.4073, Validation Acc: 0.3988\n",
      "Epoch: 102, Train Acc: 0.4054, Validation Acc: 0.3946\n",
      "Epoch: 103, Train Acc: 0.3950, Validation Acc: 0.3847\n",
      "Epoch: 104, Train Acc: 0.3749, Validation Acc: 0.3686\n",
      "Epoch: 105, Train Acc: 0.4064, Validation Acc: 0.3973\n",
      "Epoch: 106, Train Acc: 0.4005, Validation Acc: 0.3936\n",
      "Epoch: 107, Train Acc: 0.3798, Validation Acc: 0.3735\n",
      "Epoch: 108, Train Acc: 0.4035, Validation Acc: 0.3969\n",
      "Epoch: 109, Train Acc: 0.4054, Validation Acc: 0.4004\n",
      "Epoch: 110, Train Acc: 0.4004, Validation Acc: 0.3894\n",
      "Epoch: 111, Train Acc: 0.4096, Validation Acc: 0.4034\n",
      "Epoch: 112, Train Acc: 0.4062, Validation Acc: 0.3949\n",
      "Epoch: 113, Train Acc: 0.3932, Validation Acc: 0.3857\n",
      "Epoch: 114, Train Acc: 0.3993, Validation Acc: 0.3915\n",
      "Epoch: 115, Train Acc: 0.4024, Validation Acc: 0.3948\n",
      "Epoch: 116, Train Acc: 0.3963, Validation Acc: 0.3857\n",
      "Epoch: 117, Train Acc: 0.3869, Validation Acc: 0.3795\n",
      "Epoch: 118, Train Acc: 0.3885, Validation Acc: 0.3814\n",
      "Epoch: 119, Train Acc: 0.4111, Validation Acc: 0.4008\n",
      "Epoch: 120, Train Acc: 0.4060, Validation Acc: 0.3976\n",
      "Epoch: 121, Train Acc: 0.4051, Validation Acc: 0.3945\n",
      "Epoch: 122, Train Acc: 0.3847, Validation Acc: 0.3799\n",
      "Epoch: 123, Train Acc: 0.3972, Validation Acc: 0.3913\n",
      "Epoch: 124, Train Acc: 0.4175, Validation Acc: 0.4092\n",
      "Epoch: 125, Train Acc: 0.4108, Validation Acc: 0.4004\n",
      "Epoch: 126, Train Acc: 0.4067, Validation Acc: 0.3996\n",
      "Epoch: 127, Train Acc: 0.3775, Validation Acc: 0.3725\n",
      "Epoch: 128, Train Acc: 0.3614, Validation Acc: 0.3544\n",
      "Epoch: 129, Train Acc: 0.4051, Validation Acc: 0.3916\n",
      "Epoch: 130, Train Acc: 0.3960, Validation Acc: 0.3908\n",
      "Epoch: 131, Train Acc: 0.4067, Validation Acc: 0.3983\n",
      "Epoch: 132, Train Acc: 0.3919, Validation Acc: 0.3842\n",
      "Epoch: 133, Train Acc: 0.4010, Validation Acc: 0.3950\n",
      "Epoch: 134, Train Acc: 0.4125, Validation Acc: 0.4043\n",
      "Epoch: 135, Train Acc: 0.3891, Validation Acc: 0.3859\n",
      "Epoch: 136, Train Acc: 0.4023, Validation Acc: 0.3899\n",
      "Epoch: 137, Train Acc: 0.3619, Validation Acc: 0.3540\n",
      "Epoch: 138, Train Acc: 0.3627, Validation Acc: 0.3553\n",
      "Epoch: 139, Train Acc: 0.4040, Validation Acc: 0.4027\n",
      "Epoch: 140, Train Acc: 0.3808, Validation Acc: 0.3752\n",
      "Epoch: 141, Train Acc: 0.4134, Validation Acc: 0.4054\n",
      "Epoch: 142, Train Acc: 0.4091, Validation Acc: 0.3989\n",
      "Epoch: 143, Train Acc: 0.3638, Validation Acc: 0.3573\n",
      "Epoch: 144, Train Acc: 0.4150, Validation Acc: 0.4047\n",
      "Epoch: 145, Train Acc: 0.3906, Validation Acc: 0.3797\n",
      "Epoch: 146, Train Acc: 0.4068, Validation Acc: 0.4048\n",
      "Epoch: 147, Train Acc: 0.3813, Validation Acc: 0.3731\n",
      "Epoch: 148, Train Acc: 0.4130, Validation Acc: 0.4043\n",
      "Epoch: 149, Train Acc: 0.4015, Validation Acc: 0.3890\n",
      "Epoch: 150, Train Acc: 0.4081, Validation Acc: 0.4010\n",
      "Epoch: 151, Train Acc: 0.4159, Validation Acc: 0.4050\n",
      "Epoch: 152, Train Acc: 0.3958, Validation Acc: 0.3867\n",
      "Epoch: 153, Train Acc: 0.4156, Validation Acc: 0.4058\n",
      "Epoch: 154, Train Acc: 0.3992, Validation Acc: 0.3898\n",
      "Epoch: 155, Train Acc: 0.3690, Validation Acc: 0.3577\n",
      "Epoch: 156, Train Acc: 0.4083, Validation Acc: 0.3954\n",
      "Epoch: 157, Train Acc: 0.4110, Validation Acc: 0.4067\n",
      "Epoch: 158, Train Acc: 0.3641, Validation Acc: 0.3567\n",
      "Epoch: 159, Train Acc: 0.4119, Validation Acc: 0.4072\n",
      "Epoch: 160, Train Acc: 0.4170, Validation Acc: 0.4075\n",
      "Epoch: 161, Train Acc: 0.4089, Validation Acc: 0.3993\n",
      "Epoch: 162, Train Acc: 0.4027, Validation Acc: 0.3981\n",
      "Epoch: 163, Train Acc: 0.4126, Validation Acc: 0.4042\n",
      "Epoch: 164, Train Acc: 0.3948, Validation Acc: 0.3913\n",
      "Epoch: 165, Train Acc: 0.4101, Validation Acc: 0.4027\n",
      "Epoch: 166, Train Acc: 0.3900, Validation Acc: 0.3859\n",
      "Epoch: 167, Train Acc: 0.4003, Validation Acc: 0.3938\n",
      "Epoch: 168, Train Acc: 0.4140, Validation Acc: 0.4063\n",
      "Epoch: 169, Train Acc: 0.4009, Validation Acc: 0.3890\n",
      "Epoch: 170, Train Acc: 0.4007, Validation Acc: 0.3975\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = list()\n",
    "val_accuracy = list()\n",
    "epochs = 170\n",
    "for epoch in range(1, (epochs+1)):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    val_acc = test(val_loader)\n",
    "    train_accuracy.append(train_acc)\n",
    "    val_accuracy.append(val_acc)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Validation Acc: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4486b982-c70f-4ae2-aa65-9b842f251061",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (170,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plotting\u001b[39;00m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m171\u001b[39m)]\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_accuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, val_accuracy, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2814\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axes\\_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (170,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "epochs = [i for i in range(1, (epochs+1))]\n",
    "plt.plot(epochs, train_accuracy, label='train')\n",
    "plt.plot(epochs, val_accuracy, label='test')\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf07a2ef-71b6-496b-a1fa-934befa2ba58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
